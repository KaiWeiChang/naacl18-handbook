SubmissionNumber#=%=#563
FinalPaperTitle#=%=#Tensor Product Generation Networks for Deep NLP Modeling
ShortPaperTitle#=%=#Tensor Product Generation Networks for Deep NLP Modeling
NumberOfPages#=%=#11
CopyrightSigned#=%=#Qiuyuan Huang
JobTitle#==#
Organization#==#Qiuyuan Huang
Microsoft Research AI
Redmond, WA
USA
Abstract#==#We present a new approach to the design of deep networks for
natural language processing (NLP), based on the general technique
of Tensor Product Representations (TPRs) for encoding and
processing symbol structures in distributed neural networks. A
network architecture
--- the Tensor Product Generation Network (TPGN) --- is
proposed which is capable in principle of carrying out TPR
computation, but which uses unconstrained deep learning to design
its internal representations. Instantiated in a model for
image-caption generation, TPGN outperforms LSTM baselines when
evaluated on the COCO dataset. The TPR-capable structure enables
interpretation of internal representations and operations, which
prove to contain considerable grammatical content. Our
caption-generation model can be interpreted as generating
sequences of grammatical categories and retrieving words by their
categories from a plan encoded as a distributed representation.
Author{1}{Firstname}#=%=#Qiuyuan
Author{1}{Lastname}#=%=#Huang
Author{1}{Email}#=%=#qihua@microsoft.com
Author{1}{Affiliation}#=%=#Microsoft Research
Author{2}{Firstname}#=%=#Paul
Author{2}{Lastname}#=%=#Smolensky
Author{2}{Email}#=%=#paul.smolensky@gmail.com
Author{2}{Affiliation}#=%=#Microsoft Research
Author{3}{Firstname}#=%=#Xiaodong
Author{3}{Lastname}#=%=#He
Author{3}{Email}#=%=#xiaohe@microsoft.com
Author{3}{Affiliation}#=%=#JD AI Research
Author{4}{Firstname}#=%=#Li
Author{4}{Lastname}#=%=#Deng
Author{4}{Email}#=%=#deng629@gmail.com
Author{4}{Affiliation}#=%=#Microsoft Research
Author{5}{Firstname}#=%=#Dapeng
Author{5}{Lastname}#=%=#Wu
Author{5}{Email}#=%=#dpwu@ieee.org
Author{5}{Affiliation}#=%=#University of Florida

==========