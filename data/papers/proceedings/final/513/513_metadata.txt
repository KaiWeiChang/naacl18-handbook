SubmissionNumber#=%=#513
FinalPaperTitle#=%=#Discourse-Aware Neural Rewards for Coherent Text Generation
ShortPaperTitle#=%=#Discourse-Aware Neural Rewards for Coherent Text Generation
NumberOfPages#=%=#12
CopyrightSigned#=%=#Antoine Bosselut
JobTitle#==#
Organization#==#Paul G. Allen School of Computer Science & Engineering
University of Washington
Box 352350
185 E Stevens Way NE
Seattle, WA 98195
Abstract#==#In this paper, we investigate the use of discourse-aware rewards with
reinforcement learning to guide a model to generate long, coherent text. In
particular, we propose to learn neural rewards to model cross-sentence ordering
as a means to approximate desired discourse structure. Empirical results
demonstrate that a generator trained with the learned reward produces more
coherent and less repetitive text than models trained with cross-entropy or
with reinforcement learning with commonly used scores as rewards.
Author{1}{Firstname}#=%=#Antoine
Author{1}{Lastname}#=%=#Bosselut
Author{1}{Email}#=%=#antoineb@cs.washington.edu
Author{1}{Affiliation}#=%=#University of Washington
Author{2}{Firstname}#=%=#Asli
Author{2}{Lastname}#=%=#Celikyilmaz
Author{2}{Email}#=%=#asli.ca@live.com
Author{2}{Affiliation}#=%=#Microsoft Research
Author{3}{Firstname}#=%=#Xiaodong
Author{3}{Lastname}#=%=#He
Author{3}{Email}#=%=#xiaohe@microsoft.com
Author{3}{Affiliation}#=%=#JD AI Research
Author{4}{Firstname}#=%=#Jianfeng
Author{4}{Lastname}#=%=#Gao
Author{4}{Email}#=%=#jfgao@microsoft.com
Author{4}{Affiliation}#=%=#Microsoft Research
Author{5}{Firstname}#=%=#Po-Sen
Author{5}{Lastname}#=%=#Huang
Author{5}{Email}#=%=#huang146@illinois.edu
Author{5}{Affiliation}#=%=#Microsoft Research
Author{6}{Firstname}#=%=#Yejin
Author{6}{Lastname}#=%=#Choi
Author{6}{Email}#=%=#yejin@cs.washington.edu
Author{6}{Affiliation}#=%=#University of Washington / Allen Institute for Artificial Intelligence

==========