SubmissionNumber#=%=#182
FinalPaperTitle#=%=#Deep Dirichlet Multinomial Regression
ShortPaperTitle#=%=#Deep Dirichlet Multinomial Regression
NumberOfPages#=%=#10
CopyrightSigned#=%=#Adrian Benton
JobTitle#==#
Organization#==#Johns Hopkins University
3400 N. Charles Street
Baltimore, MD 21218
Abstract#==#Dirichlet Multinomial Regression (DMR) and other supervised topic models can
incorporate arbitrary document-level features to inform topic priors.  However,
their ability to model corpora are limited by the representation and selection
of these  features -- a choice the topic modeler must make. Instead, we seek
models that can learn the feature representations upon which to condition topic
selection.  We present deep Dirichlet Multinomial Regression (dDMR), a
generative topic model that simultaneously learns document feature
representations  and topics. We evaluate dDMR on three datasets: New York Times
articles with fine-grained tags, Amazon product reviews with product images,
and Reddit posts with subreddit identity.  dDMR learns representations that
outperform DMR and LDA according to heldout perplexity and are more effective
at downstream predictive tasks as the number of topics grows. Additionally,
human subjects judge dDMR topics as being more representative of associated
document features.  Finally, we find that supervision leads to faster
convergence as compared to an LDA baseline and that dDMR's model fit is less
sensitive to training parameters than DMR.
Author{1}{Firstname}#=%=#Adrian
Author{1}{Lastname}#=%=#Benton
Author{1}{Email}#=%=#adrian.benton@gmail.com
Author{1}{Affiliation}#=%=#Johns Hopkins University
Author{2}{Firstname}#=%=#Mark
Author{2}{Lastname}#=%=#Dredze
Author{2}{Email}#=%=#mdredze@cs.jhu.edu
Author{2}{Affiliation}#=%=#Johns Hopkins University

==========