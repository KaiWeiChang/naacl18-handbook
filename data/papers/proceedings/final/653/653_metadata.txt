SubmissionNumber#=%=#653
FinalPaperTitle#=%=#Neural Syntactic Generative Models with Exact Marginalization
ShortPaperTitle#=%=#Neural Syntactic Generative Models with Exact Marginalization
NumberOfPages#=%=#11
CopyrightSigned#=%=#Jan Buys
JobTitle#==#
Organization#==#This work was primarily conducted at University of Oxford (The first author is now affiliated with the University of Washington):

Department of Computer Science, University of Oxford
Wolfson Building
Parks Road
OXFORD 
OX1 3QD 
UK
Abstract#==#We present neural syntactic generative models with exact marginalization that support both dependency parsing and language modeling. Exact marginalization is made tractable through dynamic programming over shift-reduce parsing and minimal RNN-based feature sets. Our algorithms complement previous approaches by supporting batched training and enabling online computation of next word probabilities. For supervised dependency parsing, our model achieves a state-of-the-art result among generative approaches. We also report empirical results on unsupervised syntactic models and their role in language modeling. We find that our model formulation of latent dependencies with exact marginalization do not lead to better intrinsic language modeling performance than vanilla RNNs, and that parsing accuracy is not correlated with language modeling perplexity in stack-based models.
Author{1}{Firstname}#=%=#Jan
Author{1}{Lastname}#=%=#Buys
Author{1}{Email}#=%=#jbuys@cs.washington.edu
Author{1}{Affiliation}#=%=#Computer Science and Engineering, University of Washington
Author{2}{Firstname}#=%=#Phil
Author{2}{Lastname}#=%=#Blunsom
Author{2}{Email}#=%=#phil.blunsom@cs.ox.ac.uk
Author{2}{Affiliation}#=%=#University of Oxford

==========