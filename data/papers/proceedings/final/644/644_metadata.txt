SubmissionNumber#=%=#644
FinalPaperTitle#=%=#Object Counts! Bringing Explicit Detections Back into Image Captioning
ShortPaperTitle#=%=#Object Counts! Bringing Explicit Detections Back into Image Captioning
NumberOfPages#=%=#14
CopyrightSigned#=%=#Josiah Wang
JobTitle#==#
Organization#==#Department of Computer Science, The University of Sheffield
Regent Court, 211 Portobello Street
Sheffield S1 4DP
United Kingdom
Abstract#==#The use of explicit object detectors as an intermediate step to image captioning -- which used to constitute an essential stage in early work -- is often bypassed in the currently dominant end-to-end approaches, where the language model is conditioned directly on a mid-level image embedding. We argue that explicit detections provide rich semantic information, and can thus be used as an interpretable representation to better understand why end-to-end image captioning systems work well. We provide an in-depth analysis of end-to-end image captioning by exploring a variety of cues that can be derived from such object detections. Our study reveals that end-to-end image captioning systems rely on matching image representations to generate captions, and that encoding the frequency, size and position of objects are complementary and all play a role in forming a good image representation. It also reveals that different object categories contribute in different ways towards image captioning.
Author{1}{Firstname}#=%=#Josiah
Author{1}{Lastname}#=%=#Wang
Author{1}{Email}#=%=#j.k.wang@sheffield.ac.uk
Author{1}{Affiliation}#=%=#University of Sheffield
Author{2}{Firstname}#=%=#Pranava Swaroop
Author{2}{Lastname}#=%=#Madhyastha
Author{2}{Email}#=%=#p.madhyastha@sheffield.ac.uk
Author{2}{Affiliation}#=%=#University of Sheffield
Author{3}{Firstname}#=%=#Lucia
Author{3}{Lastname}#=%=#Specia
Author{3}{Email}#=%=#l.specia@sheffield.ac.uk
Author{3}{Affiliation}#=%=#University of Sheffield

==========