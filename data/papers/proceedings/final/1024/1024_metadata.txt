SubmissionNumber#=%=#1024
FinalPaperTitle#=%=#A Bi-model Based RNN Semantic Frame Parsing Model for Intent Detection and Slot Filling
ShortPaperTitle#=%=#A Bi-model Based RNN Semantic Frame Parsing Model for Intent Detection and Slot Filling
NumberOfPages#=%=#6
CopyrightSigned#=%=#Yu Wang
JobTitle#==#
Organization#==#Samsung Research America,  665 Clyde Ave, Mountain View, CA 94043
Abstract#==#Intent detection and slot filling are two main tasks for building a spoken language understanding(SLU) system. Multiple deep learning based models have demonstrated good results on these tasks . The most effective algorithms are based on the structures of sequence to sequence models (or "encoder-decoder" models), and generate the intents and semantic tags either using separate models. Most of the previous studies, however, either treat the intent detection and slot filling as two separate parallel tasks, or use a sequence to sequence model to generate both semantic tags and intent. None of the approaches consider the cross-impact between the intent detection task and the slot filling task. In this paper, new Bi-model based RNN semantic frame parsing network structures are designed to perform the intent detection and slot filling tasks jointly, by considering their cross-impact to each other using two correlated bidirectional LSTMs (BLSTM). Our Bi-model structure with a decoder achieves state-of-art result on the benchmark ATIS data, with about 0.5$\%$ intent accuracy improvement and 0.9 $\%$ slot filling improvement.
Author{1}{Firstname}#=%=#Yu
Author{1}{Lastname}#=%=#Wang
Author{1}{Email}#=%=#georgeiswang@gmail.com
Author{1}{Affiliation}#=%=#Samsung Research America
Author{2}{Firstname}#=%=#Yilin
Author{2}{Lastname}#=%=#Shen
Author{2}{Email}#=%=#benoit.shen@gmail.com
Author{2}{Affiliation}#=%=#Samsung Research America
Author{3}{Firstname}#=%=#Hongxia
Author{3}{Lastname}#=%=#Jin
Author{3}{Email}#=%=#hxjin2004@gmail.com
Author{3}{Affiliation}#=%=#Samsung Research America

==========