SubmissionNumber#=%=#582
FinalPaperTitle#=%=#Deep Communicating Agents for Abstractive Summarization
ShortPaperTitle#=%=#Deep Communicating Agents for Abstractive Summarization
NumberOfPages#=%=#14
CopyrightSigned#=%=#Antoine Bosselut
JobTitle#==#
Organization#==#Paul G. Allen School of Computer Science & Engineering
University of Washington
Box 352350
185 E Stevens Way NE
Seattle, WA 98195
Abstract#==#We present deep communicating agents in an encoder-decoder architecture to
address the challenges of representing a long document for abstractive
summarization. 
With deep communicating agents, the task of encoding a long text is divided
across multiple collaborating agents,
each in charge of a subsection of the input text. These encoders are connected
to a single decoder, trained end-to-end using
reinforcement learning to generate a focused and coherent summary. 
Empirical results demonstrate that multiple communicating encoders lead to a
higher quality summary compared to several strong baselines, including those
based on a single encoder or multiple non-communicating encoders.
Author{1}{Firstname}#=%=#Asli
Author{1}{Lastname}#=%=#Celikyilmaz
Author{1}{Email}#=%=#asli.ca@live.com
Author{1}{Affiliation}#=%=#Microsoft Research
Author{2}{Firstname}#=%=#Antoine
Author{2}{Lastname}#=%=#Bosselut
Author{2}{Email}#=%=#antoineb@cs.washington.edu
Author{2}{Affiliation}#=%=#University of Washington
Author{3}{Firstname}#=%=#Xiaodong
Author{3}{Lastname}#=%=#He
Author{3}{Email}#=%=#xiaohe@microsoft.com
Author{3}{Affiliation}#=%=#Microsoft Research
Author{4}{Firstname}#=%=#Yejin
Author{4}{Lastname}#=%=#Choi
Author{4}{Email}#=%=#yejin@cs.washington.edu
Author{4}{Affiliation}#=%=#University of Washington

==========