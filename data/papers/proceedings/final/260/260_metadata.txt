SubmissionNumber#=%=#260
FinalPaperTitle#=%=#Comparatives, Quantifiers, Proportions: a Multi-Task Model for the Learning of Quantities from Vision
ShortPaperTitle#=%=#Multi-Task Model for Learning Quantities from Vision
NumberOfPages#=%=#12
CopyrightSigned#=%=#Sandro Pezzelle
JobTitle#==#
Organization#==#CIMeC - Center for Mind/Brain Sciences
University of Trento
Corso Bettini 31, 38068 Rovereto (TN)
Italy
Abstract#==#The present work investigates whether different quantification mechanisms (set comparison, vague quantification, and proportional estimation) can be jointly learned from visual scenes by a multi-task computational model. The motivation is that, in humans, these processes underlie the same cognitive, non-symbolic ability, which allows an automatic estimation and comparison of set magnitudes. We show that when information about lower-complexity tasks is available, the higher-level proportional task becomes more accurate than when performed in isolation. Moreover, the multi-task model is able to generalize to unseen combinations of target/non-target objects. Consistently with behavioral evidence showing the interference of absolute number in the proportional task, the multi-task model no longer works when asked to provide the number of target objects in the scene.
Author{1}{Firstname}#=%=#Sandro
Author{1}{Lastname}#=%=#Pezzelle
Author{1}{Email}#=%=#sandro.pezzelle@unitn.it
Author{1}{Affiliation}#=%=#University of Trento
Author{2}{Firstname}#=%=#Ionut-Teodor
Author{2}{Lastname}#=%=#Sorodoc
Author{2}{Email}#=%=#ionut.sorodoc@gmail.com
Author{2}{Affiliation}#=%=#Universitat Pompeu Fabra
Author{3}{Firstname}#=%=#Raffaella
Author{3}{Lastname}#=%=#Bernardi
Author{3}{Email}#=%=#bernardi@disi.unitn.it
Author{3}{Affiliation}#=%=#University of Trento

==========