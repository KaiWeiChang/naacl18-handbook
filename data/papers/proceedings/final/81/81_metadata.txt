SubmissionNumber#=%=#81
FinalPaperTitle#=%=#Stacking with Auxiliary Features for Visual Question Answering
ShortPaperTitle#=%=#Stacking with Auxiliary Features for VQA
NumberOfPages#=%=#10
CopyrightSigned#=%=#Nazneen Fatema Rajani
JobTitle#==#
Organization#==#The University of Texas at Austin 
Department of Computer Science
2317 Speedway, Stop D9500
Austin, TX 78712
Abstract#==#Visual Question Answering (VQA) is a well-known and challenging task that requires systems to jointly reason about natural language and vision. Deep learning models in various forms have been the standard for solving VQA. However, some of these VQA models are better at certain types of image-question pairs than other models. Ensembling VQA models intelligently to leverage their diverse expertise is, therefore, advantageous.

Stacking With Auxiliary Features (SWAF) is an intelligent ensembling technique which learns to combine the results of multiple models using features of the current problem as context. We propose four categories of auxiliary features for ensembling for VQA. Three out of the four categories of features can be inferred from an image-question pair and do not require querying the component models. The fourth category of auxiliary features uses model-specific explanations. In this paper, we describe how we use these various categories of auxiliary features to improve performance for VQA. Using SWAF to effectively ensemble three recent systems, we obtain a new state-of-the-art. Our work also highlights the advantages of explainable AI models.
Author{1}{Firstname}#=%=#Nazneen Fatema
Author{1}{Lastname}#=%=#Rajani
Author{1}{Email}#=%=#nrajani@cs.utexas.edu
Author{1}{Affiliation}#=%=#University of Texas at Austin
Author{2}{Firstname}#=%=#Raymond
Author{2}{Lastname}#=%=#Mooney
Author{2}{Email}#=%=#mooney@cs.utexas.edu
Author{2}{Affiliation}#=%=#University of Texas at Austin

==========