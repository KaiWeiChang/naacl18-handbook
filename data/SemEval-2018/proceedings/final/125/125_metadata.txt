SubmissionNumber#=%=#125
FinalPaperTitle#=%=#YNU-HPCC at SemEval-2018 Task 12: The Argument Reasoning Comprehension Task Using a Bi-directional LSTM with Attention Model
ShortPaperTitle#=%=#The Argument Reasoning Comprehension Task Using a Bi-directional LSTM with Attention Model
NumberOfPages#=%=#5
CopyrightSigned#=%=#Quanlei Liao
JobTitle#==#
Organization#==#Yunnan University, China
Abstract#==#An argument is divided into two parts, the claim and the reason. To obtain a clearer conclusion, some additional explanation is required. In this task, the explanations are called warrants. This paper introduces a bi-directional long short term memory (Bi-LSTM) with an attention model to select a correct warrant from two to explain an argument. We address this question as a question-answering system. For each warrant, the model produces a probability that it is correct. Finally, the system chooses the highest correct probability as the answer. Ensemble learning is used to enhance the performance of the model. Among all of the participants, we ranked 15th on the test results.
Author{1}{Firstname}#=%=#Quanlei
Author{1}{Lastname}#=%=#Liao
Author{1}{Email}#=%=#paopaojingyu@hotmail.com
Author{1}{Affiliation}#=%=#Yunnan University
Author{2}{Firstname}#=%=#Xutao
Author{2}{Lastname}#=%=#Yang
Author{2}{Email}#=%=#yangxutao@ynu.edu.cn
Author{2}{Affiliation}#=%=#Yunnan University
Author{3}{Firstname}#=%=#Jin
Author{3}{Lastname}#=%=#Wang
Author{3}{Email}#=%=#wangjin@ynu.edu.cn
Author{3}{Affiliation}#=%=#Yunnan University
Author{4}{Firstname}#=%=#Xuejie
Author{4}{Lastname}#=%=#Zhang
Author{4}{Email}#=%=#xjzhang@ynu.edu.cn
Author{4}{Affiliation}#=%=#Yunnan University

==========