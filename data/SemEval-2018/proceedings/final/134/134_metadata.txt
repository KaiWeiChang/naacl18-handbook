SubmissionNumber#=%=#134
FinalPaperTitle#=%=#YNU Deep at SemEval-2018 Task 12: A BiLSTM Model with Neural Attention for Argument Reasoning Comprehension
ShortPaperTitle#=%=#A BiLSTM Model with Neural Attention for Argument Reasoning Comprehension
NumberOfPages#=%=#4
CopyrightSigned#=%=#Peng Ding
JobTitle#==#
Organization#==#Yunnan University,Yunnan, P.R. China
Abstract#==#This paper describes the system submitted to SemEval-2018 Task 12 (The Argument Reasoning Comprehension Task). Enabling a computer to understand a text so that it can answer comprehension questions is still a challenging goal of NLP. We propose a Bidirectional LSTM (BiLSTM) model that reads two sentences separated by a delimiter to determine which warrant is correct. We extend this model with a neural attention mechanism that encourages the model to make reasoning over the given claims and reasons. Officially released results show that our system ranks 6th among 22 submissions to this task.
Author{1}{Firstname}#=%=#Peng
Author{1}{Lastname}#=%=#Ding
Author{1}{Email}#=%=#894828866@qq.com
Author{1}{Affiliation}#=%=#YunNan University
Author{2}{Firstname}#=%=#Xiaobing
Author{2}{Lastname}#=%=#Zhou
Author{2}{Email}#=%=#zhouxb.cn@gmail.com
Author{2}{Affiliation}#=%=#Yunnan University

==========