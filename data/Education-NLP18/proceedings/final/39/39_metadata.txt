SubmissionNumber#=%=#39
FinalPaperTitle#=%=#Estimating Linguistic Complexity for Science Texts
ShortPaperTitle#=%=#Estimating Linguistic Complexity for Science Texts
NumberOfPages#=%=#11
CopyrightSigned#=%=#Farah Nadeem
JobTitle#==#
Organization#==#University of Washington, 1410 NE Campus Parkway, Seattle WA, 98195
Abstract#==#Evaluation of text difficulty is important both for downstream tasks like text simplification, and for supporting educators in classrooms. Existing work on automated text complexity analysis uses linear models with engineered knowledge-driven features as inputs. While this offers interpretability, these models have lower accuracy for shorter texts. Traditional readability metrics have the additional drawback of not generalizing to informational texts such as science. We propose a neural approach, training on science and other informational texts, to mitigate both problems. Our results show that neural methods outperform knowledge-based linear models for short texts, and have the capacity to generalize to genres not present in the training data.
Author{1}{Firstname}#=%=#Farah
Author{1}{Lastname}#=%=#Nadeem
Author{1}{Email}#=%=#farahn@uw.edu
Author{1}{Affiliation}#=%=#University of Washington
Author{2}{Firstname}#=%=#Mari
Author{2}{Lastname}#=%=#Ostendorf
Author{2}{Email}#=%=#ostendor@u.washington.edu
Author{2}{Affiliation}#=%=#University of Washington

==========