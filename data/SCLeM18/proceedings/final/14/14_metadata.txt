SubmissionNumber#=%=#14
FinalPaperTitle#=%=#Subword-level Composition Functions for Learning Word Embeddings
ShortPaperTitle#=%=#Subword-level Composition Functions for Learning Word Embeddings
NumberOfPages#=%=#11
CopyrightSigned#=%=#bofang li
JobTitle#==#
Organization#==#Renmin University of China
No. 59 Zhongguancun Street, Haidian District Beijing, 100872, P.R. China

Tokyo Institute of Technology
2-12-1 Ookayama, Meguro-ku, Tokyo 152-8550 Japan
Abstract#==#Subword-level information is crucial for capturing the meaning and morphology of words, especially for out-of-vocabulary entries. We propose CNN- and RNN-based subword-level composition functions for learning word embeddings, and systematically compare them with popular word-level and subword-level models (Skip-Gram and FastText). Additionally, we propose a hybrid training scheme in which a pure subword-level model is trained jointly with a conventional word-level embedding model based on lookup-tables. This increases the fitness of all types of subword-level word embeddings; the word-level embeddings can be discarded after training, leaving only compact subword-level representation with much smaller data volume. We evaluate these embeddings on a set of intrinsic and extrinsic tasks, showing that subword-level models have advantage on tasks related to morphology and datasets with high OOV rate, and can be combined with other types of embeddings.
Author{1}{Firstname}#=%=#Bofang
Author{1}{Lastname}#=%=#Li
Author{1}{Email}#=%=#libofang@ruc.edu.cn
Author{1}{Affiliation}#=%=#Renmin University of China
Author{2}{Firstname}#=%=#Aleksandr
Author{2}{Lastname}#=%=#Drozd
Author{2}{Email}#=%=#alexander.drozd@gmail.com
Author{2}{Affiliation}#=%=#Tokyo Institute of Technology
Author{3}{Firstname}#=%=#Tao
Author{3}{Lastname}#=%=#Liu
Author{3}{Email}#=%=#tliu@ruc.edu.cn
Author{3}{Affiliation}#=%=#Renmin University of China
Author{4}{Firstname}#=%=#Xiaoyong
Author{4}{Lastname}#=%=#Du
Author{4}{Email}#=%=#duyong@ruc.edu.cn
Author{4}{Affiliation}#=%=#Renmin University of China

==========