Children learn word meanings by tapping into the commonalities across different situations in which words are used. However, early word learning experiences have a high level of uncertainty. For a word, there are many possible meanings in the environment (referential uncertainty) and for a meaning, there are multiple possible words in the utterance (linguistic uncertainty). Is keeping track of the co-occurrence of words and meanings enough to learn the correct meanings of words? Through a set of computational studies, we show that to successfully learn word meanings in the face of uncertainty, a model needs to implement two types of competitions: words competing for association to a meaning helps with linguistic uncertainty, and features competing for a word limits referential uncertainty. Our results also confirm that a model that does not implement any types of competition can only learn high-frequency words where the uncertainty is limited.
