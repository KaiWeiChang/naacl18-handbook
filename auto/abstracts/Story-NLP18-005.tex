We present a novel approach for event extraction and abstraction from movie descriptions. Our event frame consists of `who'', ``did what'' ``to whom'', ``where'', and ``when''. We formulate our problem using a recurrent neural network, enhanced with structural features extracted from syntactic parser, and trained using curriculum learning by progressively increasing the difficulty of the sentences. Our model serves as an intermediate step towards question answering systems, visual storytelling, and story completion tasks. We evaluate our approach on MovieQA dataset.
